models:
  vision:
    name: "openai/clip-vit-base-patch32"
    embedding_dim: 512

  audio:
    name: "openai/whisper-small"
    embedding_dim: 512

  text:
    name: "sentence-transformers/all-MiniLM-L12-v2"
    embedding_dim: 384

  fusion:
    input_dim: 1408   # 512 + 512 + 384
    hidden_dims: [768, 384]
    output_dim: 2

processing:
  window_size_sec: 3
  frame_sampling_fps: 0.33
  batch_size: 24
  device: "cuda"

selection:
  max_clips_per_video: 4
  min_clip_sec: 25
  max_clip_sec: 60
